{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Saving Data to External Files\n",
    "This notebook gives examples of how to write out selected data from [`GBTFitsLoad`](https://dysh.readthedocs.io/en/latest/modules/dysh.fits.html#module-dysh.fits.gbtfitsload) and how to save \n",
    "[`Spectrum`](https://dysh.readthedocs.io/en/latest/modules/dysh.spectra.html#module-dysh.spectra.spectrum), \n",
    "[`Scan`](https://dysh.readthedocs.io/en/latest/modules/dysh.spectra.html#module-dysh.spectra.scan), and \n",
    "[`ScanBlock`](https://dysh.readthedocs.io/en/latest/modules/dysh.spectra.html#dysh.spectra.scan.ScanBlock) to different formats.\n",
    "\n",
    "You can find a copy of this tutorial as a Jupyter notebook [here](https://github.com/GreenBankObservatory/dysh/blob/main/notebooks/examples/dataIO.ipynb) or download it by right clicking  <a href=\"https://raw.githubusercontent.com/GreenBankObservatory/dysh/refs/heads/main/notebooks/examples/dataIO.ipynb\" download>here</a> and selecting \"Save Link As\".\n",
    "\n",
    "## Loading Modules\n",
    "We start by loading the modules we will use for this example. \n",
    "\n",
    "For display purposes, we use the static (non-interactive) matplotlib backend in this tutorial. However, you can tell `matplotlib` to use the `ipympl` backend to enable interactive plots. This is only needed if working on jupyter lab or notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set interactive plots in jupyter.\n",
    "#%matplotlib ipympl\n",
    "\n",
    "# These modules are required for loading and reading data.\n",
    "from dysh.fits.gbtfitsload import GBTFITSLoad\n",
    "from dysh.spectra.spectrum import Spectrum\n",
    "\n",
    "# We will use matplotlib for plotting.\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# These modules are only used to download the data.\n",
    "from pathlib import Path\n",
    "from dysh.util.download import from_url"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## Data Retrieval\n",
    "\n",
    "Download the example SDFITS data, if necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"http://www.gb.nrao.edu/dysh/example_data/positionswitch/data/AGBT05B_047_01/AGBT05B_047_01.raw.acs/AGBT05B_047_01.raw.acs.fits\"\n",
    "savepath = Path.cwd() / \"data\"\n",
    "savepath.mkdir(exist_ok=True) # Create the data directory if it does not exist.\n",
    "filename = from_url(url, savepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "## Data Loading\n",
    "\n",
    "Next, we use `GBTFITSLoad` to load the data, and then its `summary` method to inspect its contents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdfits = GBTFITSLoad(filename)\n",
    "sdfits.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "### Calibrate a position switched scan.  \n",
    "\n",
    "This returns a `ScanBlock` containing one [`PSScan`](https://dysh.readthedocs.io/en/latest/modules/dysh.spectra.html#dysh.spectra.scan.PSScan) with 11 integrations for the ON position and 11 integrations for the OFF position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps_scan_block = sdfits.getps(scan=51, ifnum=0, plnum=0, fdnum=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of integrations = {ps_scan_block[0].nrows}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "Get the time average of the calibrated data. This method returns a `Spectrum`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "ta = ps_scan_block.timeaverage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "ta.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "## Reading and Writing Individual Spectra"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "###  Inputs and Outputs\n",
    "`dysh` supports output to text files in a variety of [formats familiar to users of astropy](https://docs.astropy.org/en/stable/io/ascii/index.html#id1):\n",
    "* basic\n",
    "* commented_header\n",
    "* ECSV\n",
    "* fixed_width\n",
    "* IPAC\n",
    "* MRT\n",
    "* votable\n",
    "\n",
    "The following lines of code define some of the available formats in a list, and then loop over them saving the calibrated data in each format.\n",
    "We use the `overwrite=True` parameter to avoid errors if the files already exist on disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the formats in a list.\n",
    "fmt = [ \n",
    "    \"basic\",\n",
    "    \"commented_header\",\n",
    "    \"ecsv\",\n",
    "    \"fixed_width\",\n",
    "    \"ipac\",\n",
    "    \"mrt\",\n",
    "    \"votable\",\n",
    "]\n",
    "\n",
    "# Define the output directory and create it if it does not exists already.\n",
    "output_dir = Path.cwd() / \"output\"\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Loop over formats writing the calibrated spectrum.\n",
    "for f in fmt:\n",
    "    file = output_dir / f\"testwrite.{f}\"\n",
    "    ta.write(file, format=f, overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "We can also write a `Spectrum` to FITS format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "ta.write(output_dir / \"testwrite.fits\", format=\"fits\", overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "We can read spectra in FITS and a few formats. [As noted in astropy, ECSV ](https://docs.astropy.org/en/stable/io/ascii/ecsv.html#ecsv-format) is the only ASCII format that can make a lossless output-input roundtrip and thus reproduce an original spectrum.\n",
    "\n",
    "We use the `Spectrum.read` method to read the saved data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = Spectrum.read(output_dir / \"testwrite.fits\", format=\"fits\")\n",
    "s1.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "s2 = Spectrum.read(output_dir / \"testwrite.ecsv\", format=\"ecsv\")\n",
    "s2.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "### GBTIDL ASCII format\n",
    "`dysh` can read text files created by GBTIDL's `write_ascii` function. However, those files do not provide sufficient metadata to fully recreate the spectrum.  (For instance, they do not have complete sky coordinate information.)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.gb.nrao.edu/dysh/example_data/onoff-L/gbtidl-data/onoff-L_gettp_156_intnum_0_HEL.ascii\"\n",
    "filename_ascii = from_url(url, savepath)\n",
    "s3 = Spectrum.read(filename_ascii, format='gbtidl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(s3, \"\\n\", s3.meta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "`dysh` can even read compressed ASCII files. Note these data have velocity on the spectral axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.gb.nrao.edu/dysh/example_data/onoff-L/gbtidl-data/onoff-L_getps_152_RADI-HEL.ascii.gz\"\n",
    "filename_ascii_gz = from_url(url, savepath)\n",
    "s4 = Spectrum.read(filename_ascii_gz, format='gbtidl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(s4, \"\\n\", s4.meta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "#### Plot \n",
    "To plot the spectrum contained in the ascii files you have to use `matplotlib`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.xlabel(f\"Velocity ({s4.meta['VELDEF']}) [{s4.spectral_axis.unit}]\")\n",
    "plt.ylabel(f\"$T_A$ [{s4.flux.unit}]\")\n",
    "plt.plot(s4.spectral_axis, s4.flux)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {},
   "source": [
    "## Writing Multiple Calibrated Spectra to SDFITS\n",
    "You can write the calibrated data from a `ScanBlock` to the SDFITS format.\n",
    "If there are multiple scans in the `ScanBlock`, they will all be written to the same SDFITS (useful for `gbtgridder`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps_scan_block.write(output_dir / \"scanblock.fits\", overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30",
   "metadata": {},
   "source": [
    "## Reading Calibrated SDFITS\n",
    "\n",
    "To load the saved data, we use the same function we used to load the raw data, `GBTFITSLoad`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps_scan_block_read = GBTFITSLoad(output_dir / \"scanblock.fits\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32",
   "metadata": {},
   "source": [
    "This is treated the same was as the raw data, so the same methods are available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps_scan_block_read.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34",
   "metadata": {},
   "source": [
    "However, since the data is already calibrated, trying to fetch the data using calibration methods like `getps` or `getnod` will result in errors.\n",
    "Instead, we can use the `gettp` method or `getspec`.\n",
    "\n",
    "### Using `gettp`\n",
    "\n",
    "If we use `gettp`, then we will get all of the integrations as a `ScanBlock` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "tp_read = ps_scan_block_read.gettp(scan=51, ifnum=0, plnum=0, fdnum=0)\n",
    "print(f\"Number of integrations: {tp_read[0].nint}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36",
   "metadata": {},
   "source": [
    "We can access individual integration through the `calibrated` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "ta_read_0a = tp_read[0].getspec(0)\n",
    "ta_read_0a.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38",
   "metadata": {},
   "source": [
    "### Using `getspec`\n",
    "\n",
    "Now we do the same using `getspec`. This method takes as input the row number we want to retrieve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "ta_read_0b = ps_scan_block_read.getspec(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "ta_read_0b.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41",
   "metadata": {},
   "source": [
    "If we take the difference, it is zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "(ta_read_0a.data - ta_read_0b.data).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43",
   "metadata": {},
   "source": [
    "## Writing Out Selected Data from `GBTFITSLoad`\n",
    "The `write()` method of `GBTFITSLoad` supports down-selection of data. \n",
    "Data can be selected on any SDFITS column.\n",
    "\n",
    "In the following call to `GBTFITSLoad.write` we will select a single polarization (`plnum=1`), and only the first five integrations of each scan (`intnum=range(5)`). We also set `overwrite=True` to avoid errors if the file already exists, and request that the output be saved into a single file (`multifile=False`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdfits.write(output_dir / \"mydata.fits\", plnum=1, \n",
    "             intnum=range(5), overwrite=True, multifile=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45",
   "metadata": {},
   "source": [
    "These data, can of course, be read back in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdfits2 = GBTFITSLoad(output_dir / \"mydata.fits\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdfits2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48",
   "metadata": {},
   "source": [
    "### Writing SDFITS to Multiple Files \n",
    "If the data came from multiple files, for instance VEGAS banks, then by default they are written to multiple files, so\n",
    "`sdfits.write('mydata.fits')`\n",
    "would write to mydata0.fits, mydata1.fits, ... mydataN.fits.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
