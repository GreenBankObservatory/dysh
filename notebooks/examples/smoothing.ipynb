{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Smoothing\n",
    "\n",
    "This notebook shows how to use `dysh` to smooth a spectrum.   For the example below we will use data from the Position-Switch example. The following dysh commands are the simplest to get and smooth a spectrum (leaving out all the function arguments):\n",
    "\n",
    "      sdf = GBTFITSLoad()\n",
    "      sb = sdf.getps()\n",
    "      ta = sb.timeaverage()\n",
    "      tb = ta.smooth()\n",
    "      tb.plot()\n",
    "\n",
    "or if you wish to make use of the Python object chaining:\n",
    "\n",
    "       GBTFITSLoad().getps().timeaverage().smooth().plot()\n",
    "\n",
    "You can find a copy of this tutorial as a Jupyter notebook [here](https://github.com/GreenBankObservatory/dysh/blob/main/notebooks/examples/smoothing.ipynb) or download it by right clicking  <a href=\"https://raw.githubusercontent.com/GreenBankObservatory/dysh/refs/heads/main/notebooks/examples/smoothing.ipynb\" download>here</a> and selecting \"Save Link As\".\n",
    "\n",
    "## Loading Modules\n",
    "We start by loading the modules we will use for the data reduction. \n",
    "\n",
    "For display purposes, we use the static (non-interactive) `matplotlib` backend in this tutorial. However, you can tell `matplotlib` to use the `ipympl` backend to enable interactive plots. This is only needed if working on `jupyter` lab or notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "import"
    ]
   },
   "outputs": [],
   "source": [
    "# Set interactive plots in jupyter.\n",
    "#%matplotlib ipympl\n",
    "\n",
    "# These modules are required for working with the data.\n",
    "from dysh.fits.gbtfitsload import GBTFITSLoad\n",
    "\n",
    "# These modules are only used to download the data.\n",
    "from pathlib import Path\n",
    "from dysh.util.download import from_url"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## Data Retrieval\n",
    "\n",
    "Download the example SDFITS data, if necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "wget"
    ]
   },
   "outputs": [],
   "source": [
    "url = \"http://www.gb.nrao.edu/dysh/example_data/positionswitch/data/AGBT05B_047_01/AGBT05B_047_01.raw.acs/AGBT05B_047_01.raw.acs.fits\"\n",
    "savepath = Path.cwd() / \"data\"\n",
    "savepath.mkdir(exist_ok=True) # Create the data directory if it does not exist.\n",
    "filename = from_url(url, savepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "## Data Loading\n",
    "\n",
    "Next, we use `GBTFITSLoad` to load the data, and then its `summary` method to inspect its contents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "load"
    ]
   },
   "outputs": [],
   "source": [
    "sdfits = GBTFITSLoad(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdfits.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "## Data Reduction\n",
    "\n",
    "### Calibration and Time Averaging\n",
    "\n",
    "This test data has 8 scans making up 4 pairs of OnOff observations. We will calibrate all of the OnOff scan pairs, time average them and then compare the results with and without smoothing. To calibrate all of the scans, we can omit the scan keyword when using the `sdfits.getps` method.\n",
    "\n",
    "*Technical note*: ``getps`` returns a **ScanBlock** with in this case four `PSScan`s, since there are four pairs of OnOff observations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "timeaverage",
     "test"
    ]
   },
   "outputs": [],
   "source": [
    "scan_block = sdfits.getps(ifnum=0, plnum=0, fdnum=0)\n",
    "ta = scan_block.timeaverage()\n",
    "ta.plot(xaxis_unit=\"chan\", yaxis_unit=\"mK\", ymin=100, ymax=600, grid=True)\n",
    "\n",
    "# Define a string for printing the spectrum statistics.\n",
    "fmt_str = \"mean: {mean:.4f} median: {median:.4f} rms: {rms:.4f} min: {min:.2f} max: {max:.2f}\"\n",
    "print(f\"Stats : {fmt_str}\".format(**ta[5000:14000].stats()))\n",
    "print(\"Expect: mean: 0.2708 K median: 0.2711 K rms: 0.0359 K min: 0.14 K max: 0.42 K\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "The noise in the time averaged spectrum is 36 mK. However, this has not been baseline subtracted and there is a slope in the continuum."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "### Baseline Removal\n",
    "\n",
    "We remove the slope by baseline fitting an order 1 polynomial from the data while ignoring the channels that contain a signal. This is done using the `Spectrum.baseline()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "ta.baseline(model=\"poly\", degree=1, exclude=[(14000,18000)], remove=True)\n",
    "ta.plot(xaxis_unit=\"chan\", yaxis_unit=\"mK\", ymin=-200, ymax=300, grid=True)\n",
    "print(f\"Stats : {fmt_str}\".format(**ta[5000:14000].stats()))\n",
    "print(\"Expect: mean: 0.0005 K median: 0.0005 K rms: 0.0358 K min: -0.13 K max: 0.16 K\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "### Smooth in a Few Ways\n",
    "\n",
    "By default smoothing will also decimate the signal, to (roughly) make each channel independant of the next. This assuming the input signal had independant channels. If the input was oversampled by a factor of 2, the smoothed signal will be as well, although you can manually decimate by a different value too, for example by using ``decimate=8`` .\n",
    "\n",
    "Since we smooth to a gauss of FWHM 16 channels, the noise should go down by a factor of 4 (36 mK to 9 mK)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts1 = ta.smooth('gaussian', 16)\n",
    "ts1.plot(xaxis_unit=\"chan\", yaxis_unit=\"mK\", ymin=-200, ymax=300, grid=True)\n",
    "print(f\"Stats : {fmt_str}\".format(**ts1[5000//16:14000//16].stats()))\n",
    "print(\"Expect: mean: 0.0005 K median: 0.0004 K rms: 0.0075 K min: -0.02 K max: 0.03 K\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "The noise is now 8 mK, very close to the improvement we expected.\n",
    "\n",
    "Now smoothing by 320 channels should result in a noise of $55/\\sqrt{320}$ or 2 mK. In this case we will use a box as the convolving kernel.\n",
    "\n",
    "We will also estimate the correlation between channels by comparing the noise in the spectra with the noise in the spectra when we subtract adjacent channels (using `roll=1` in `Spectrum.stats()`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts2 = ta.smooth('box', 320)\n",
    "ts2.plot(xaxis_unit=\"chan\", yaxis_unit=\"mK\", ymin=-200, ymax=300, grid=True)\n",
    "\n",
    "print(f\"Stats : {fmt_str}\".format(**ts2[5000//320:14000//320].stats()))\n",
    "rratio = ts2[5000//320:14000//320].stats(roll=1)[\"rms\"]/ts2[5000//320:14000//320].stats(roll=0)[\"rms\"]\n",
    "print(f\"Rolled rms/rms ratio: {rratio}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "The noise in the smoothed spectrum is ~2 mK, as expected.\n",
    "\n",
    "The rolled RMS ratio is very close to 1, so neighboring channels are not related. If you would decimate by 160, you would see this ratio drop. Be sure to adjust the range of channels for any new computations of the spectrum statistics (`Spectrum.stats`)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "### Smoothing the Reference (\"OFF\") Scans\n",
    "\n",
    "Under certain circumstances it can be beneficial to (boxcar) smooth the reference (OFF) signal before the usual\n",
    "(ON-OFF)/OFF calibration. \n",
    "\n",
    "*Technical note*:  if you want to achieve identical results to GBTIDL, the width of the boxcar needs to be odd.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "scan_block2 = sdfits.getps(ifnum=0, plnum=0, fdnum=0, smoothref=31)\n",
    "ta2 = scan_block2.timeaverage()\n",
    "ta2.plot(xaxis_unit=\"chan\", yaxis_unit=\"mK\", ymin=100, ymax=600, grid=True)\n",
    "print(f\"Stats : {fmt_str}\".format(**ta2[5000:14000].stats()))\n",
    "print(\"Expect: mean: 0.2694 K median: 0.2690 K rms: 0.0272 K min: 0.08 K max: 0.78 K\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "When smoothing the reference spectra, the noise in the time average of the calibrated spectrum is 27 mK.\n",
    "\n",
    "We repeat the baseline subtraction using the same model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "ta2.baseline(model=\"poly\", degree=1, exclude=[(14000,18000)], remove=True)\n",
    "ta2.plot(xaxis_unit=\"chan\", yaxis_unit=\"mK\", ymin=-200, ymax=300, grid=True)\n",
    "print(f\"Stats : {fmt_str}\".format(**ta2[5000:14000].stats()))\n",
    "print(\"Expect: mean: 0.0009 K median: 0.0007 K rms: 0.0270 K min: -0.19 K max: 0.50 K\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "We could smooth this spectrum the normal way, as was done a few cells ago, and not much difference is visible, except for the noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts3 = ta2.smooth('box', 320)\n",
    "ts3.plot(xaxis_unit=\"chan\", yaxis_unit=\"mK\", ymin=-200, ymax=300, grid=True)\n",
    "print(f\"Stats : {fmt_str}\".format(**ts3[5000//320:14000//320].stats()))\n",
    "rratio = ts3[5000//320:14000//320].stats(roll=1)[\"rms\"]/ts3[5000//320:14000//320].stats(roll=0)[\"rms\"]\n",
    "print(f\"Rolled rms/rms ratio: {rratio}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "The RMS has gone down (2.4 mK to 2.3 mK), but the signal correlation has also increased from 1.06 to 1.10. This increase is due to the added correlation of the reference smoothing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "## Successive Smoothing\n",
    "\n",
    "Smoothing with a Gaussian twice in a row should be the same as smoothing with a single Gaussian of the square root of the sum of their squares. Note that the **width** is the final width (FWHM) of the smoothing operation. We need to ignore decimation here, which is the third argument (`decimate=-1`), otherwise the spectra will have a different number of channels.\n",
    "\n",
    "We plot the difference between the two smoothing routes, which is perhaps surprisingly still below 1e-8. It is not closer to 0 due to the finite range the Gaussian is sampled (to 4 sigma)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts5a = ta.smooth('gaussian', width=3, decimate=-1).smooth('gaussian', width=5, decimate=-1)\n",
    "ts5b = ta.smooth('gaussian', width=5, decimate=-1)\n",
    "diff = ts5a-ts5b\n",
    "diff.plot(ymin=-0.00001, ymax=0.00001)\n",
    "\n",
    "fmt_str = \"mean: {mean:.4g} median: {median:.4g} rms: {rms:.4g} min: {min:.2g} max: {max:.2g}\"\n",
    "print(f\"Stats : {fmt_str}\".format(**diff[5000:14000].stats()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "toc": {
   "base_numbering": 0
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
