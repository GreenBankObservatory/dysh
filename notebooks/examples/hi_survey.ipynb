{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# HI Survey\n",
    "\n",
    "This tutorial goes through the data reduction of position switched observations of the 21 cm HI line. The data used for this tutorial is part of the [New Reference Catalog of Extragalactic HI Observations\n",
    "](https://greenbankobservatory.org/~koneil/HIsurvey/index.shtml) by [Karen O'Neil](https://greenbankobservatory.org/~koneil/). For more details about how the observations were set up, please refer to the [GBTdocs HI Position Switched (psw) Spectrum tutorial](https://gbtdocs.readthedocs.io/en/latest/tutorials/hi_psw_tutorial.html#) or the [survey article](https://greenbankobservatory.org/~koneil/paps/HIsurvey.html).\n",
    "\n",
    "Some basic information about the observations. The observations use position switching, and in some cases, the data is recorded without firing a noise diode, so that it is not possible to derive a system temperature from those records alone. In those cases, we will use observations close in time when the noise diodes where fired.\n",
    "\n",
    "You can find a copy of this tutorial as a Jupyter notebook [here](https://github.com/GreenBankObservatory/dysh/blob/main/notebooks/examples/hi_survey.ipynb) or download it by right clicking  <a href=\"https://raw.githubusercontent.com/GreenBankObservatory/dysh/refs/heads/main/notebooks/examples/hi_survey.ipynb\" download>here</a> and selecting \"Save Link As\".\n",
    "\n",
    "## Loading Modules\n",
    "We start by loading the modules we will use for the data reduction. \n",
    "\n",
    "For display purposes, we use the static (non-interactive) matplotlib backend in this tutorial. However, you can tell `matplotlib` to use the `ipympl` backend to enable interactive plots. This is only needed if working on jupyter lab or notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set interactive plots in jupyter.\n",
    "#%matplotlib ipympl\n",
    "\n",
    "# These modules are required for the data reduction.\n",
    "from dysh.fits.gbtfitsload import GBTFITSLoad\n",
    "from astropy import units as u\n",
    "import numpy as np\n",
    "\n",
    "# This module is used for custom plotting.\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# We will use this module to compare with published results.\n",
    "import pandas as pd\n",
    "\n",
    "# These modules are only used to download the data.\n",
    "from pathlib import Path\n",
    "from dysh.util.download import from_url"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## Data Retrieval\n",
    "\n",
    "Download the example SDFITS data, if necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"http://www.gb.nrao.edu/dysh/example_data/hi-survey/data/AGBT04A_008_02.raw.acs/AGBT04A_008_02.raw.acs.fits\"\n",
    "savepath = Path.cwd() / \"data\"\n",
    "savepath.mkdir(exist_ok=True) # Create the data directory if it does not exist.\n",
    "filename = from_url(url, savepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "## Data Loading\n",
    "\n",
    "Next, we use {py:class}`GBTFITSLoad <dysh.fits.GBTFITSLoad>` to load the data, and then its {py:class}`summary <dysh.fits.GBTFITSLoad.summary>` method to inspect its contents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdfits = GBTFITSLoad(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdfits.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "There is a total of 81 scans in this data set, all used a single spectral window (IF), two polarizations (PLNUM), and a single feed (FDNUM).\n",
    "\n",
    "## Data Reduction\n",
    "\n",
    "### Noise Diode Temperature\n",
    "\n",
    "The first step in calibrating the data is to determine the temperature of the noise diode(s).\n",
    "It is a known issue with GBT observations that the values provided are only accurate to $\\sim20\\%$ (see e.g., [Goddy et al 2020](https://ui.adsabs.harvard.edu/abs/2020RNAAS...4....3G/abstract)).\n",
    "The data we are working with contains eight scans of 3C286, a known calibrator source (see e.g., [Perley & Butler 2017](https://ui.adsabs.harvard.edu/abs/2017ApJS..230....7P/abstract)).\n",
    "We use the last two (scans 226 and 227), as the other seem to have problems, to derive the temperature of the noise diode(s).\n",
    "\n",
    "#### Computing the Noise Diode Temperature\n",
    "\n",
    "To derive the temperature of the noise diode(s) we use the {py:class}`gettcal <dysh.fits.gbtfitsload.GBTFITSLoad.gettcal>` method.\n",
    "This method is described in more detail in another tutorial.\n",
    "`gettcal` requires a `zenith_opacity` as input.\n",
    "Since this an L-band observation, we use a value of 0.08.\n",
    "The exact value does not have a significant impact on the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tcal = sdfits.gettcal(scan=226, ifnum=0, plnum=0, fdnum=0, zenith_opacity=0.08)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "The return from `gettcal` is a {py:class}`TCal <dysh.spectra.tcal.TCal>` object, which is a child of {py:class}`Spectrum <dysh.spectra.spectrum.Spectrum>`, so it has the same methods and properties, plus a `name` and `snu` (the flux density of the calibrator) properties.\n",
    "To get the mean value of the noise diode temperature over the inner $80\\%$ of the spectral window we use the {py:class}`TCal.get_tcal <dysh.spectra.tcal.TCal.get_tcal>` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "tcal_0 = tcal.get_tcal()\n",
    "print(tcal_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "Thus the temperature of the noise diode for polarization 0 is $20.49$ K.\n",
    "We do the same for the second polarization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "tcal = sdfits.gettcal(scan=226, ifnum=0, plnum=1, fdnum=0, zenith_opacity=0.08)\n",
    "tcal_1 = tcal.get_tcal()\n",
    "print(tcal_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "#### Updating the Noise Diode Temperature\n",
    "It is possible to provide the value of the noise diode temperature using the `t_cal` argument to the calibration methods.\n",
    "An alternative is to update the metadata of the `GBTFITSLoad` object with the new values.\n",
    "Here we use the second approach.\n",
    "First we need to determine where the derived noise temperatures are applicable.\n",
    "This is important as there are two choices for the noise diode temperature, high or low.\n",
    "We start by determining what noise diode was use for scan 226, we one we used to derive the noise diode temperature.\n",
    "We leverage the summary, and its `add_columns` and `scan` arguments.\n",
    "The type of noise diode used is stored in the \"CALTYPE\" column of an SDFITS.\n",
    "We also show the noise diode temperature stored in the metadata, in the \"TCAL\" column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdfits.summary(scan=226, add_columns=\"CALTYPE, TCAL\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "So, for scan 226 the \"high\" noise diode was used, and its value is not that far from what we found earlier.\n",
    "Where else was it used?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdfits.summary(add_columns=\"CALTYPE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "All, but a single scan (which we won't use in this tutorial), used the \"high\" noise diode.\n",
    "\n",
    "\n",
    "Now we update all of the rows, with the corresponding noise diode temperature.\n",
    "We have to update both polarizations separately.\n",
    "In this example we only have one spectral window and one beam, but if we had more, we would also need to separate those cases, as each beam can have a different noise diode and the temperature of the noise diode is a function of frequency.\n",
    "\n",
    "To access the metadata, we use the `index` property of the `GBTFITSLoad` object, which is a `pandas.DataFrame` object.\n",
    "Then we select only those rows where \"PLNUM\" is equal to the value we are interested in (e.g., `sdfits[\"PLNUM\"] == 0`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdfits.index().loc[sdfits[\"PLNUM\"] == 0, \"TCAL\"] = tcal_0\n",
    "sdfits.index().loc[sdfits[\"PLNUM\"] == 1, \"TCAL\"] = tcal_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "Now we show how to double check that the values where updated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdfits[\"TCAL\"][ (sdfits[\"SCAN\"] == 226) & (sdfits[\"PLNUM\"] == 0) ], tcal_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdfits[\"TCAL\"][ (sdfits[\"SCAN\"] == 226) & (sdfits[\"PLNUM\"] == 1) ], tcal_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "The above shows that the values were successfully updated.\n",
    "\n",
    "Now we can proceed calibrating the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "### Single On/Off Pair\n",
    "We will start by reducing data for a single pair of position switched scans, which used the noise diodes. We will use scan 270. First, we calibrate the data for a single polarization, `plnum=0`. We use the {py:class}`getps <dysh.fits.gbtfitsload.GBTFITSLoad.getps>` method of `GBTFITSLoad`, which returns a {py:class}`ScanBlock <dysh.spectra.scan.ScanBlock>`. Since we are calibrating a single pair of position switched scans, the use of a `ScanBlock` won't be evident, but we will see it when we calibrate multiple pairs of observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "pssb0 = sdfits.getps(scan=270, plnum=0, ifnum=0, fdnum=0)\n",
    "pssb0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "The return is a `ScanBlock` with a single {py:class}`PSScan <dysh.spectra.scan.PSScan>` in it. We can extract information from the observations by querying the different attributes of the `PSScan`, like the system temperature in K (`tsys`), or exposure time in seconds (`exposure`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "pssb0[0].tsys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "pssb0[0].exposure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "pssb0[0].scan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "pssb0[0].plnum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "pssb0[0].ifnum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31",
   "metadata": {},
   "source": [
    "Notice that the `PSScan` says it has a scan number (`scan`) of 271. This is because `dysh` can tell that the on-source observation has a scan number of 271, and the off-source observation is in scan 270.\n",
    "\n",
    "#### Inspecting Individual Integrations\n",
    "\n",
    "If we want to have a look at the calibrated data, integration by integration, we can use the `_calibrated` attribute of the `PSScan`. This returns an array with rows corresponding to the integrations, and columns to the channel number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "pssb0[0]._calibrated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33",
   "metadata": {},
   "source": [
    "We can also retrieve the calibrated integrations as {py:class}`Spectrum <dysh.spectra.spectrum.Spectrum>` objects using the `calibrated` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "pssb0_int0 = pssb0[0].getspec(0)\n",
    "pssb0_int0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35",
   "metadata": {},
   "source": [
    "{py:class}`Spectrum <dysh.spectra.spectrum.Spectrum>` objects have a variety of methods, such as {py:class}`plot <dysh.spectra.spectrum.Spectrum.plot>`, {py:class}`smooth <dysh.spectra.spectrum.Spectrum.smooth>`, and {py:class}`baseline <dysh.spectra.spectrum.Spectrum.baseline>`. Here we use `plot` to look a the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "pssb0_int0.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37",
   "metadata": {},
   "source": [
    "The y-axis can be adjusted during the call to `plot`, through the `ymin` and `ymax` arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "pssb0_int0.plot(ymin=-5, ymax=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39",
   "metadata": {},
   "source": [
    "Since this is a single integration, there's not much to see. Let's work on a time average now.\n",
    "\n",
    "#### Time Averaging Integrations\n",
    "\n",
    "Time averaging can be done using the {py:class}`timeaverage <dysh.spectra.scan.ScanBlock.timeaverage>` method of a `Scan` or `ScanBlock`. By default time averaging uses the following weights: \n",
    "$$\n",
    "\\frac{T^{2}_{sys}}{\\Delta\\nu\\Delta t}\n",
    "$$\n",
    "with $T_{sys}$ the system temperature, $\\Delta\\nu$ the channel width and $\\Delta t$ the integration time. In `dysh` these are set using `weights='tsys'` (the default).\n",
    "\n",
    "`timeaverage` will return a `Spectrum` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps0_spec = pssb0.timeaverage()\n",
    "ps0_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps0_spec.plot(ymin=-5, ymax=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42",
   "metadata": {},
   "source": [
    "The noise is lower, and there are hints of a signal. Let's smooth the data to further reduce the noise. \n",
    "\n",
    "#### Smoothing\n",
    "\n",
    "Smoothing is done with the {py:class}`smooth <dysh.spectra.spectrum.Spectrum.smooth>` method. By default it decimates the spectrum, so it only retains independent samples. In this case we smooth using a Gaussian kernel with a width of 16 channels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps0_spec_smo = ps0_spec.smooth(\"gauss\", 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps0_spec_smo.plot(ymin=-5, ymax=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45",
   "metadata": {},
   "source": [
    "We have to zoom in further to see the signal. We also limit the x-axis range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps0_spec_smo.plot(ymin=-0.2, ymax=0.5, xmin=1.397e9, xmax=1.400e9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47",
   "metadata": {},
   "source": [
    "#### Polarization Averaging\n",
    "\n",
    "While inspecting the data we saw that there are two polarizations. We can average them together to further reduce the noise by a factor $\\sqrt{2}$. The second polarization can be calibrated following the above steps, but setting `plnum=1`. Here we also demonstrate the use of chaining to do the data reduction. This refers to using multiple commands in a chain, like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps1_spec_smo = sdfits.getps(scan=270, plnum=1, ifnum=0, fdnum=0).timeaverage().smooth(\"gauss\", 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps1_spec_smo.plot(ymin=-0.2, ymax=0.5, xmin=1.397e9, xmax=1.400e9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50",
   "metadata": {},
   "source": [
    "Now we average the smoothed spectra for both polarizations using the {py:class}`average <dysh.spectra.spectrum.Spectrum.average>` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps_spec_smo = ps0_spec_smo.average([ps1_spec_smo])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps_spec_smo.plot(ymin=-0.2, ymax=0.5, xmin=1.397e9, xmax=1.400e9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53",
   "metadata": {},
   "source": [
    "#### Statistics\n",
    "\n",
    "Now we will compare the noise properties of the spectra. For this we leverage the ability to slice spectra. First, we replot the spectra over the whole x-range to find a good frequency range where to compute statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps_spec_smo.plotter.reset()\n",
    "ps_spec_smo.plot(ymin=-0.2, ymax=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55",
   "metadata": {},
   "source": [
    "We use the range between 1394 MHz and 1398 MHz, and then compute the statistics over this range using the {py:class}`stats <dysh.spectra.spectrum.Spectrum.stats>` method of a `Spectrum`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = slice(1394*u.MHz, 1398*u.MHz)\n",
    "ps_spec_smo[s].stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57",
   "metadata": {},
   "source": [
    "Now for the individual polarizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps0_spec_smo[s].stats(), ps1_spec_smo[s].stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59",
   "metadata": {},
   "source": [
    "The individual polarizations had an rms of $\\approx0.0255$ K, and the average an rms of $0.02$ K. Thus, the average has a noise a factor of $0.9\\sqrt{2}$ lower than the individual polarizations. That is $10\\%$ higher than expected.\n",
    "\n",
    "#### Baseline Subtraction\n",
    "\n",
    "Now we will subtract a baseline from the averaged spectrum. For this we use the {py:class}`baseline <dysh.spectra.spectrum.Spectrum.baseline>` method. It is important to use a range of frequencies that will not bias the baseline fit. We exclude the range at the low-frequency end of the spectral window, up to 1394 MHz, and the range that contains the spectral line, between 1398 and 1400 MHz. In this case we use a polynomial of order 1 as our baseline model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60",
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude = [(1*u.GHz,1.394*u.GHz),(1.398*u.GHz,1.4*u.GHz)]\n",
    "ps_spec_smo.baseline(1, model=\"poly\", exclude=exclude, remove=True)\n",
    "ps_spec_smo.plot(ymin=-0.2, ymax=0.5, xmin=1.397e9, xmax=1.400e9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps_spec_smo[s].stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps_spec_smo.plot(ymax=0.25, ymin=-0.1, xaxis_unit=\"km/s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63",
   "metadata": {},
   "source": [
    "The mean and median are closer to zero now.\n",
    "\n",
    "### Multiple On/Off Pairs\n",
    "\n",
    "Now that we understand how to process a single pair of On/Off scans, we proceed to calibrate a bunch of them. In `dysh` this can be accomplished by either, giving a list of scans to the calibration routines, or by selecting the scans based on another property of the data. \n",
    "\n",
    "#### Using a List of Scans\n",
    "\n",
    "First we need to figure out all of the scans for a particular source. For U8503, there is a single pair of On/Off scans, so we need to use a different source. We use 3C286, for which we have scans 220, 221, 222, 223, 224, 225, 226, 227 using OffOn with the noise diodes. \n",
    "\n",
    "We could have figured out which scans using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64",
   "metadata": {},
   "outputs": [],
   "source": [
    "scan_list = list(set(sdfits[\"SCAN\"][(sdfits[\"OBJECT\"] == \"3C286\") & \\\n",
    "                     (sdfits[\"PROC\"] == \"OffOn\") & (sdfits[\"CAL\"] == \"T\")]))\n",
    "sorted(scan_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps0_obj = sdfits.getps(scan=scan_list, plnum=0, ifnum=0, fdnum=0).timeaverage()\n",
    "ps1_obj = sdfits.getps(scan=scan_list, plnum=1, ifnum=0, fdnum=0).timeaverage()\n",
    "ps_obj = ps0_obj.average(ps1_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps_obj.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67",
   "metadata": {},
   "source": [
    "Since 3C286 is a continuum source, we can see Galactic HI absorption against the continuum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps_obj.plot(xmin=1.420e9, xmax=1.421e9, ymin=15, ymax=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69",
   "metadata": {},
   "source": [
    "#### Using Selection\n",
    "\n",
    "We can do the same by using the {py:class}`selection <dysh.fits.gbtfitsload.GBTFITSLoad.selection>` method before calling `getps`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdfits.select(object=\"3C286\", proc=\"OffOn\")\n",
    "ps0_obj_b = sdfits.getps(plnum=0, ifnum=0, fdnum=0).timeaverage()\n",
    "ps1_obj_b = sdfits.getps(plnum=1, ifnum=0, fdnum=0).timeaverage()\n",
    "ps_obj_b = ps0_obj_b.average(ps1_obj_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps_obj_b.plot(xmin=1.420e9, xmax=1.421e9, ymin=15, ymax=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72",
   "metadata": {},
   "source": [
    "Once you are done calibrating, you should clear the selection to have access to all the data again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdfits.selection.clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74",
   "metadata": {},
   "source": [
    "#### Using Arguments\n",
    "\n",
    "We can accomplish the same by specifying the `object` and procedure type (`proc`) during the call to `getps`. Any of the calibration methods ({py:class}`getps <dysh.fits.gbtfitsload.GBTFITSLoad.getps>`, {py:class}`getfs <dysh.fits.gbtfitsload.GBTFITSLoad.getfs>`, {py:class}`getnod <dysh.fits.gbtfitsload.GBTFITSLoad.getnod>`, {py:class}`getsigref <dysh.fits.gbtfitsload.GBTFITSLoad.getsigref>`, {py:class}`subbeamnod <dysh.fits.gbtfitsload.GBTFITSLoad.subbeamnod>`, ) can take as argument any of the [columns of an SDFITS file](https://dysh.readthedocs.io/en/latest/reference/sdfits_files/gbt_sdfits.html#data). When used this way, the calibration routine will only use the data that satisfies the conditions, so for example, if we use `sdfits.getps(object=\"3C286\", plnum=0, ifnum=0, fdnum=0)` the calibration routine will only use data that has the column \"OBJECT\" equal to \"3C286\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps0_obj_c = sdfits.getps(plnum=0, ifnum=0, fdnum=0, object=\"3C286\", proc=\"OffOn\").timeaverage()\n",
    "ps1_obj_c = sdfits.getps(plnum=1, ifnum=0, fdnum=0, object=\"3C286\", proc=\"OffOn\").timeaverage()\n",
    "ps_obj_c = ps0_obj_c.average(ps1_obj_c)\n",
    "ps_obj_c.plot(xmin=1.420e9, xmax=1.421e9, ymin=15, ymax=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76",
   "metadata": {},
   "source": [
    "### Calibration Without Noise Diodes\n",
    "\n",
    "Most of the scans in this example did not use the noise diode. In this case we need to provide a value for the system temperature so that the data can be calibrated. For this particular observation, there is one Track observing procedure associated with the OffOn pairs. For these Track observations, the noise diode was fired, so we can use them to figure out the system temperature.\n",
    "\n",
    "We will work on observations of U11627. For this source the Track scan is 320, and the OffOn pairs are in scans 316, 317, 318 and 319.\n",
    "\n",
    "First we use {py:class}`gettp <dysh.fits.gbtfitsload.GBTFITSLoad.gettp>` to figure out the system temperature from the Track scan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77",
   "metadata": {},
   "outputs": [],
   "source": [
    "tp0 = sdfits.gettp(scan=320, plnum=0, ifnum=0, fdnum=0).timeaverage()\n",
    "tp1 = sdfits.gettp(scan=320, plnum=1, ifnum=0, fdnum=0).timeaverage()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78",
   "metadata": {},
   "source": [
    "The system temperature is stored in the `meta` dictionary of each `Spectrum`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"System temperature for plnum={tp0.meta['PLNUM']}: {tp0.meta['TSYS']:.2f} K\")\n",
    "print(f\"System temperature for plnum={tp1.meta['PLNUM']}: {tp1.meta['TSYS']:.2f} K\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80",
   "metadata": {},
   "source": [
    "Now we use these values to calibrate the data. The system temperature is provided for the calibration methods through the `t_sys` argument. It is assumed to be in K."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdfits.select(object=\"U11627\", proc=\"OffOn\")\n",
    "ps0_wtsys = sdfits.getps(plnum=0, ifnum=0, fdnum=0, t_sys=tp0.meta['TSYS']).timeaverage()\n",
    "ps1_wtsys = sdfits.getps(plnum=1, ifnum=0, fdnum=0, t_sys=tp1.meta['TSYS']).timeaverage()\n",
    "ps_wtsys = ps0_wtsys.average(ps1_wtsys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps_wtsys.plot(ymin=-0.5, ymax=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83",
   "metadata": {},
   "source": [
    "Now we smooth and remove a baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps_wtsys_smo = ps_wtsys.smooth(\"gauss\", 16)\n",
    "ps_wtsys_smo.baseline(1, model=\"poly\", exclude=[(1*u.GHz,1.393*u.GHz),(1.397*u.GHz,1.399*u.GHz)], remove=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps_wtsys_smo.plot(ymin=-0.2, ymax=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdfits.selection.clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87",
   "metadata": {},
   "source": [
    "### Combining Off Spectra\n",
    "\n",
    "In some situations we would like to have more flexibility during calibration to specify what will be the Off or reference spectrum used for calibration. In these cases we can use the {py:class}`GBTFITSLoad.getsigref <dysh.fits.gbtfitsload.GBTFITSLoad.getsigref>` function. This function takes as inputs a scan number, or list of them, to be used as On, and a reference spectrum, or scan number (only one in this case). Here we will combine the two Off source spectra from the previous calibration before calibrating the data.\n",
    "\n",
    "We use {py:class}`gettp <dysh.fits.gbtfitsload.GBTFITSLoad.gettp>` to produce the reference spectrum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88",
   "metadata": {},
   "outputs": [],
   "source": [
    "tp_ref0 = sdfits.gettp(scan=[316,318], plnum=0, ifnum=0, fdnum=0, t_sys=tp0.meta['TSYS']).timeaverage()\n",
    "tp_ref1 = sdfits.gettp(scan=[316,318], plnum=1, ifnum=0, fdnum=0, t_sys=tp1.meta['TSYS']).timeaverage()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89",
   "metadata": {},
   "source": [
    "Now use `getsigref` to do the calibration. Since we specified the system temperature in the previous call to `gettp`, we do not need to provide it again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdfits.select(object=\"U11627\", proc=\"OffOn\")\n",
    "ps0_wtsys_tpr = sdfits.getsigref(scan=[317,319], ref=tp_ref0, plnum=0, ifnum=0, fdnum=0).timeaverage()\n",
    "ps1_wtsys_tpr = sdfits.getsigref(scan=[317,319], ref=tp_ref1, plnum=1, ifnum=0, fdnum=0).timeaverage()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91",
   "metadata": {},
   "source": [
    "Average both polarizations, smooth and remove a baseline like before so we can compare the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps_wtsys_tpr = ps0_wtsys_tpr.average(ps1_wtsys_tpr)\n",
    "ps_wtsys_tpr_smo = ps_wtsys_tpr.smooth(\"gauss\", 16)\n",
    "ps_wtsys_tpr_smo.baseline(1, model=\"poly\", \n",
    "                          exclude=[(1*u.GHz,1.393*u.GHz),(1.397*u.GHz,1.399*u.GHz)], \n",
    "                          remove=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps_wtsys_tpr_smo.plot(ymin=-0.2, ymax=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94",
   "metadata": {},
   "source": [
    "Now compare the noise in the end products."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = slice(1.393*u.GHz, 1.396*u.GHz)\n",
    "rms_tpr = ps_wtsys_tpr_smo[s].stats()[\"rms\"]\n",
    "rms = ps_wtsys_smo[s].stats()[\"rms\"]\n",
    "print(f\"Ratio of rms: {rms_tpr/rms}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96",
   "metadata": {},
   "source": [
    "In this case, using a combined reference spectrum improved the noise by an insignificant amount, $\\approx0.02\\%$.\n",
    "\n",
    "### Working in Flux Units\n",
    "\n",
    "So far we have calibrated the data to antenna temperature units, but it is also possible to work on flux units. To do so, we must provide a zenith opacity value and specify that we want the data in Jy, using the `zenith_opacity` and `units` parameters. Since this data is observed at 1.4 GHz, we use a small value for the zenith opacity, 0.08. For more details on how to find the zenith opacity for your observations, please see [this guide](https://gbtdocs.readthedocs.io/en/latest/how-tos/data_reduction/calculate_opacity.html). We also repeat the previous calibration steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps0_wtsys_tpr = sdfits.getsigref(scan=[317,319], ref=tp_ref0, plnum=0, ifnum=0, fdnum=0, \n",
    "                                 units=\"flux\", zenith_opacity=0.08).timeaverage()\n",
    "ps1_wtsys_tpr = sdfits.getsigref(scan=[317,319], ref=tp_ref1, plnum=1, ifnum=0, fdnum=0, \n",
    "                                 units=\"flux\", zenith_opacity=0.08).timeaverage()\n",
    "ps_wtsys_tpr = ps0_wtsys_tpr.average(ps1_wtsys_tpr)\n",
    "ps_wtsys_tpr_smo = ps_wtsys_tpr.smooth(\"gauss\", 16)\n",
    "ps_wtsys_tpr_smo.baseline(1, model=\"poly\", \n",
    "                          exclude=[(1*u.GHz,1.393*u.GHz),(1.397*u.GHz,1.399*u.GHz)], \n",
    "                          remove=True)\n",
    "ps_wtsys_tpr_smo.plot(ymin=-30, ymax=80, yaxis_unit=\"mJy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98",
   "metadata": {},
   "source": [
    "## Measuring Line Properties\n",
    "\n",
    "`Spectrum` objects provide a convenience function for analysis of HI profiles based on the Curve of Growth (CoG) method by [Yu et al. (2020)](https://ui.adsabs.harvard.edu/abs/2020ApJ...898..102Y/abstract), through the {py:class}`cog <dysh.spectra.spectrum.Spectrum.cog>` method. The implementation of this method can retrieve line parameters in a fully automated way, however, this is likely to work only in high signal-to-noise cases (>10). In low signal-to-noise cases, additional inputs are required to aid the method. In particular, it helps to provide a good estimate of the central velocity of the line using the `vc` parameter and/or restricting the range over which the method is applied, either by slicing the `Spectrum` or using the `bchan` and `echan` parameters.\n",
    "\n",
    "First we apply the method blindly, ignoring the edge channels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99",
   "metadata": {},
   "outputs": [],
   "source": [
    "line_props = ps_wtsys_tpr_smo[60:-60].cog()\n",
    "line_props"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100",
   "metadata": {},
   "source": [
    "Plot the results along with the central velocity and the line width that encompasses 95% of the total flux."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(ps_wtsys_tpr_smo[60:].spectral_axis.to(\"km/s\"), ps_wtsys_tpr_smo[60:].flux)\n",
    "plt.axvline(line_props[\"vel\"].value, c=\"r\", alpha=0.5, ls=\":\")\n",
    "plt.axvline((line_props[\"vel\"] - line_props[\"width\"][0.95]/2).value, c=\"g\")\n",
    "plt.axvline((line_props[\"vel\"] + line_props[\"width\"][0.95]/2).value, c=\"g\")\n",
    "plt.xlim(4500, 5200)\n",
    "plt.xlabel(\"Velocity (km/s)\")\n",
    "plt.ylabel(\"Flux (Jy)\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102",
   "metadata": {},
   "source": [
    "The results are not great. Use CoG again, but providing a range of channels through the `bchan` and `echan` parameters (these can only be channel numbers)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103",
   "metadata": {},
   "outputs": [],
   "source": [
    "line_props_wrange = ps_wtsys_tpr_smo[60:-60].cog(bchan=line_props[\"bchan\"], echan=line_props[\"echan\"])\n",
    "line_props_wrange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104",
   "metadata": {},
   "outputs": [],
   "source": [
    "line_props_wrange = ps_wtsys_tpr_smo[60:-60].cog(bchan=750, echan=1100)\n",
    "line_props_wrange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(ps_wtsys_tpr_smo[60:].spectral_axis.to(\"km/s\"), ps_wtsys_tpr_smo[60:].flux)\n",
    "plt.axvline(line_props_wrange[\"vel\"].value, c=\"r\", alpha=0.5, ls=\":\")\n",
    "plt.axvline((line_props_wrange[\"vel\"] - line_props_wrange[\"width\"][0.95]/2).value, c=\"g\")\n",
    "plt.axvline((line_props_wrange[\"vel\"] + line_props_wrange[\"width\"][0.95]/2).value, c=\"g\")\n",
    "plt.xlim(4500, 5200)\n",
    "plt.xlabel(\"Velocity (km/s)\")\n",
    "plt.ylabel(\"Flux (Jy)\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "106",
   "metadata": {},
   "source": [
    "Much better!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "107",
   "metadata": {},
   "source": [
    "## Putting it all Together\n",
    "\n",
    "Now we can use what we have learned to process all of the observations.\n",
    "We will loop over all the objects, calibrating the data.\n",
    "For the system temperature, we use the last Track observation associated with a given object.\n",
    "Since there may have been issues with the previous Track observations if they had to be repeated (for example, for U11578 the first Track observation did not fire the noise diode).\n",
    "We process \"U8503\" individually, because there is no \"Track\" scan for it but the OffOn observations did use the noise diode.\n",
    "\n",
    "We put all the steps in a function, `process`. This makes it easier to reuse the code, and modify it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(sdfits, object, results, track=True):\n",
    "    \"\"\"\n",
    "    Function to calibrate the AGBT04A_008_02 observations.\n",
    "    This function was heavily tailored to work with this\n",
    "    observations and there is no guarantee it would work with\n",
    "    other data.\n",
    "    \"\"\"\n",
    "    \n",
    "    o = object\n",
    "\n",
    "    if track:\n",
    "        # Use only the last Track observation for every object.\n",
    "        tp0 = sdfits.gettp(ifnum=0, plnum=0, fdnum=0, object=o, proc=\"Track\")[-1].timeaverage()\n",
    "        tp1 = sdfits.gettp(ifnum=0, plnum=1, fdnum=0, object=o, proc=\"Track\")[-1].timeaverage()\n",
    "    \n",
    "        # Calibrate using the system temperature of the Track scan.\n",
    "        ps0 = sdfits.getps(ifnum=0, plnum=0, fdnum=0, object=o, proc=\"OffOn\", \n",
    "                           t_sys=tp0.meta[\"TSYS\"], units=\"flux\", zenith_opacity=0.08).timeaverage()\n",
    "        ps1 = sdfits.getps(ifnum=0, plnum=1, fdnum=0, object=o, proc=\"OffOn\", \n",
    "                           t_sys=tp1.meta[\"TSYS\"], units=\"flux\", zenith_opacity=0.08).timeaverage()\n",
    "\n",
    "    else:\n",
    "        # Calibrate computing the system temperature from the Off scan.\n",
    "        ps0 = sdfits.getps(ifnum=0, plnum=0, fdnum=0, object=o, proc=\"OffOn\", \n",
    "                           units=\"flux\", zenith_opacity=0.08).timeaverage()\n",
    "        ps1 = sdfits.getps(ifnum=0, plnum=1, fdnum=0, object=o, proc=\"OffOn\", \n",
    "                           units=\"flux\", zenith_opacity=0.08).timeaverage()\n",
    "\n",
    "    # Average polarizations.\n",
    "    ps = ps0.average(ps1)\n",
    "\n",
    "    # Smooth.\n",
    "    ps_smo = ps.smooth(\"gauss\", 16)\n",
    "\n",
    "    # Determine if the Galactic HI line is present, and if so,\n",
    "    # ignore it during the baseline fit.\n",
    "    idx0 = np.argmin(abs(ps_smo.spectral_axis - 1.420*u.GHz))\n",
    "    idxf = np.argmin(abs(ps_smo.spectral_axis - 1.421*u.GHz))\n",
    "    idx0,idxf = np.sort([idx0,idxf])\n",
    "    if idx0 == 0 or idx0 == len(ps_smo.data) - 1 or idxf == 0 or idxf == len(ps_smo.data) - 1:\n",
    "        exclude=[(0,100),(500,1250),(2047-100,2047)]\n",
    "    else:\n",
    "        exclude=[(0,100),(500,1250),(idx0,idxf),(2047-100,2047)]\n",
    "\n",
    "    # Baseline subtraction.\n",
    "    ps_smo.baseline(degree=1, model=\"poly\", exclude=exclude, remove=True)\n",
    "\n",
    "    # Measure line properties using Curve of Growth.\n",
    "    # Ignore 100 channels in each edge, and compute the\n",
    "    # CoG over the inner (750,1250) channels.\n",
    "    cog = ps_smo[100:-100].cog(bchan=750, echan=1250, width_frac=[0.95])\n",
    "\n",
    "    # Save the measured line properties.\n",
    "    # In particular, the object name, flux and its width.\n",
    "    results[\"name\"].append(o.replace(\"U\", \"UGC \"))\n",
    "    for k in [\"flux\", \"flux_error\"]:\n",
    "        results[k].append(cog[k.replace(\"error\", \"std\")].to(\"Jy km/s\").value)\n",
    "    for k in [\"width\", \"width_error\"]:\n",
    "        results[k].append(cog[k.replace(\"error\", \"std\")][0.95].to(\"km/s\").value)\n",
    "\n",
    "measured = {\"name\": [],\n",
    "            \"flux\": [],\n",
    "            \"flux_error\": [],\n",
    "            \"width\": [],\n",
    "            \"width_error\": [],\n",
    "           }\n",
    "\n",
    "sdfits.selection.clear()\n",
    "# Start at object 4 since the previous ones were calibration observations.\n",
    "for o in sdfits.udata(\"OBJECT\")[4:]:\n",
    "\n",
    "    if o ==  \"U8503\":\n",
    "        track = False\n",
    "    else:\n",
    "        track = True\n",
    "    \n",
    "    process(sdfits, o, measured, track=track)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109",
   "metadata": {},
   "source": [
    "### Compare with the Literature\n",
    "\n",
    "We can compare the results obtained here with those listed by the author in [this page](https://greenbankobservatory.org/~koneil/HIsurvey/results_all.html). The results are also provided as a text table. We download this table and parse its contents. We save the flux and $W_{20}$ (the width of the line at 20% of the peak flux) values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_file = from_url(\"https://greenbankobservatory.org/~koneil/HIsurvey/results_all.dat\", savepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\"name\": [],\n",
    "        \"flux\": [],\n",
    "        \"flux_error\": [],\n",
    "        \"width\": [],\n",
    "        \"width_error\": []\n",
    "       }\n",
    "\n",
    "# Open the file.\n",
    "with open(table_file) as f:\n",
    "    lines = f.readlines()\n",
    "    # Loop over lines extracting the data we are interested in.\n",
    "    # The column numbers are provided in the header of the text file.\n",
    "    for line in lines:\n",
    "        if line.lstrip().startswith(\"\\\\\"):\n",
    "            continue\n",
    "        data[\"name\"].append(\" \".join(line[1:14].strip().split()))\n",
    "        try:\n",
    "            data[\"flux\"].append(float(line[49:53].strip()))\n",
    "        except ValueError:\n",
    "            data[\"flux\"].append(np.nan)\n",
    "        data[\"flux_error\"].append(float(line[54:57].strip()))\n",
    "        try:\n",
    "            data[\"width\"].append(float(line[58:61].strip()))\n",
    "        except ValueError:\n",
    "            data[\"width\"].append(np.nan)\n",
    "        data[\"width_error\"].append(float(line[62:64].strip()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "112",
   "metadata": {},
   "source": [
    "Now create `pandas.DataFrame` objects to manipulate the measured and literature results. We use `DataFrame` as it provides a convenient way of handling the data. While loading the data, we sort it by \"name\". We will also remove sources that do not appear in both data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to DataFrame and sort.\n",
    "df_obs = pd.DataFrame.from_dict(measured).sort_values(by=\"name\")\n",
    "df_lit = pd.DataFrame.from_dict(data).sort_values(by=\"name\")\n",
    "\n",
    "# Find sources present in both data sets.\n",
    "shared_names = set(df_obs[\"name\"]) & set(df_lit[\"name\"])\n",
    "\n",
    "# Keep only the sources found above.\n",
    "df_obs_s = df_obs[df_obs[\"name\"].isin(shared_names)]\n",
    "df_lit_s = df_lit[df_lit[\"name\"].isin(shared_names)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "114",
   "metadata": {},
   "source": [
    "For example, for object 11627 the flux is $2.3\\pm0.0$ Jy km s$^{-1}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115",
   "metadata": {},
   "outputs": [],
   "source": [
    "# With Pandas.\n",
    "print(df_lit_s.loc[df_lit_s[\"name\"] == \"UGC 11627\"])\n",
    "\n",
    "print(\"\\n\") # Blank line.\n",
    "\n",
    "# Without Pandas.\n",
    "idx = data[\"name\"].index(\"UGC 11627\")\n",
    "print(f\"Flux for UGC 11627: {data['flux'][idx]} +- {data['flux_error'][idx]} Jy km/s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116",
   "metadata": {},
   "source": [
    "Now that we have the results, plot them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(dpi=150)\n",
    "# Plot a 1-to-1 line using the observed values.\n",
    "plt.plot(sorted(df_obs_s[\"flux\"]), sorted(df_obs_s[\"flux\"]), \"k--\")\n",
    "plt.errorbar(df_obs_s[\"flux\"], df_lit_s[\"flux\"], \n",
    "             xerr=df_obs_s[\"flux_error\"], \n",
    "             yerr=df_lit_s[\"flux_error\"], \n",
    "             marker=\".\", ls=\"\", ms=5)\n",
    "for n,o,l in zip(df_obs_s[\"name\"], df_obs_s[\"flux\"], df_lit_s[\"flux\"]):\n",
    "    plt.text(o, l, n, ha=\"center\", va=\"bottom\")\n",
    "plt.tight_layout()\n",
    "plt.xlabel(\"Measured Flux (Jy km s$^{-1}$)\")\n",
    "plt.ylabel(\"Literature Flux (Jy km s$^{-1}$)\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "118",
   "metadata": {},
   "source": [
    "There are significant differences between the tabulated values and those measured from this data set.\n",
    "At the time of writing we do not understand the origin of the difference. As far as we can tell, processing the data in GBTIDL produces equivalent results as those presented here (the differences in flux measurements are <1 Jy km s$^{-1}$). Stay tuned for an update."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(dpi=150)\n",
    "# Plot a 1-to-1 line using the observed values.\n",
    "plt.plot(sorted(df_obs_s[\"width\"]), sorted(df_obs_s[\"width\"]), \"k--\")\n",
    "plt.errorbar(df_obs_s[\"width\"], df_lit_s[\"width\"], \n",
    "             xerr=df_obs_s[\"width_error\"], \n",
    "             yerr=df_lit_s[\"width_error\"], \n",
    "             marker=\".\", ls=\"\", ms=5)\n",
    "for n,o,l in zip(df_obs_s[\"name\"], df_obs_s[\"width\"], df_lit_s[\"width\"]):\n",
    "    plt.text(o, l, n, ha=\"center\", va=\"bottom\")\n",
    "plt.tight_layout()\n",
    "plt.xlabel(\"Measured Width (km s$^{-1}$)\")\n",
    "plt.ylabel(\"Literature Width (km s$^{-1}$)\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120",
   "metadata": {},
   "source": [
    "The widths agree much better, since they do not depend on the flux calibration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
