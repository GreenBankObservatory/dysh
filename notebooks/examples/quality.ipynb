{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Data Quality\n",
    "\n",
    "This notebook shows some of the data quality functions associated with a {py:class}`Spectrum <dysh.spectra.spectrum.Spectrum>`. The data used for this example is taken from position switched observations of NGC5291 at 21 cm (AGBT05B_047_01).\n",
    "\n",
    "The following {py:class}`Spectrum <dysh.spectra.spectrum.Spectrum>` functions will be discussed:\n",
    "\n",
    "* {py:class}`stats <dysh.spectra.spectrum.Spectrum.stats>` : statistics of a spectrum\n",
    "* {py:class}`roll <dysh.spectra.spectrum.Spectrum.roll>` : subtract the data by its rolled version to discover channel correlations and/or ripples in the spectrum\n",
    "* {py:class}`radiometer <dysh.spectra.spectrum.Spectrum.radiometer>` : adherence of spectrum to the radiometer equation\n",
    "* {py:class}`normalness <dysh.spectra.spectrum.Spectrum.normalness>` : p-value for null hypothesis that the data comes from a normal distribution\n",
    "* {py:class}`snr <dysh.spectra.spectrum.Spectrum.snr>` : signal-to-noise ratio, either channel or flux based\n",
    "* {py:class}`sratio <dysh.spectra.spectrum.Spectrum.sratio>` : flux ratio, a number between -1 and 1, if there is signal, 0 if none\n",
    "* {py:class}`cog <dysh.spectra.spectrum.Spectrum.cog>` : curve of growth\n",
    "\n",
    "<!--\n",
    "```\n",
    "stats         - statistics of a spectrum\n",
    "roll          - a series of rolls (1,2,3...) to discover channel correlations and/or ripples in the spectrum\n",
    "radiometer    - adherence of spectrum to the radiometer equation\n",
    "snr           - signal/noise ratio, either channel or flux based\n",
    "sratio        - flux ratio, an indiction of a number between -1 and 1, if there is signal, 0 if none.\n",
    "normalness    - likelyhood noise is a gaussian, returned as a p-value  (p>0.05 means signal is gaussian(\n",
    "cog           - curve of growth - can be useful to automatically determine where signal is\n",
    "```\n",
    "-->\n",
    "## Loading Modules\n",
    "\n",
    "We start by loading the modules we will use in this notebook. \n",
    "\n",
    "For display purposes, we use the static (non-interactive) `matplotlib` backend in this tutorial. However, you can tell `matplotlib` to use the `ipympl` backend to enable interactive plots. This is only needed if working on `jupyter` lab or notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "import"
    ]
   },
   "outputs": [],
   "source": [
    "# Set interactive plots in jupyter.\n",
    "#%matplotlib ipympl # Uncomment for interactive plots.\n",
    "\n",
    "# These modules are required for the data reduction.\n",
    "import numpy as np\n",
    "from astropy import units as u\n",
    "from dysh.util.files import dysh_data\n",
    "from dysh.spectra.spectrum import Spectrum\n",
    "from dysh.fits.gbtfitsload import GBTFITSLoad\n",
    "\n",
    "from dysh.log import init_logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set logging to INFO level.\n",
    "# This is only required in notebooks.\n",
    "init_logging(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## Data Loading\n",
    "\n",
    "We use the data from the tests for {py:class}`getps <dysh.fits.gbtfitsload.GBTFITSLoad.getps>` (AGBT05B_047_01).\n",
    "We load the data using {py:class}`GBTFITSLoad <dysh.fits.gbtfitsload.GBTFITSLoad>`, and then its {py:class}`summary <dysh.fits.gbtfitsload.GBTFITSLoad.summary>` method to inspect its contents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "load"
    ]
   },
   "outputs": [],
   "source": [
    "filename = dysh_data(test=\"getps\")      # AGBT05B_047_01/AGBT05B_047_01.raw.acs\n",
    "sdfits = GBTFITSLoad(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdfits.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "## Data Reduction\n",
    "\n",
    "First we extract a (time-averaged) spectrum from the first scan. \n",
    "If you recall from the [Position-Switched example](https://dysh.readthedocs.io/en/latest/tutorials/examples/positionswitch.html), both edges have some problems, and for the purpose of this we remove some edge channels by slicing the {py:class}`Spectrum <dysh.spectra.spectrum.Spectrum>`. \n",
    "We end by plotting the resulting {py:class}`Spectrum <dysh.spectra.spectrum.Spectrum>` using channels for the x-axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "getps",
     "test"
    ]
   },
   "outputs": [],
   "source": [
    "sp1 = sdfits.getps(scan=51, ifnum=0, plnum=0, fdnum=0).timeaverage()[5000:30000]\n",
    "plot1 = sp1.plot(xaxis_unit='chan');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "From the plot we see that there is a clear signal between channels 10000 and 13000.\n",
    "We will need to avoid these channels in some of the examples below to reduce their impact on the computed data quality metrics.\n",
    "\n",
    "## Statistics\n",
    "We start by showing the use of the {py:class}`stats <dysh.spectra.spectrum.Spectrum.stats>` method.\n",
    "This computes the mean, median, rms, mininum, maximum, number of points and number of points that are not-a-number (NaN).\n",
    "We can compute these statistics over a subset of channels by slicing the {py:class}`Spectrum <dysh.spectra.spectrum.Spectrum>` before calling the method.\n",
    "We do this for the first 10000 channels and the last 10000 channels of the previously obtained spectrum, not the full 32768 channel spectrum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First 10,000 channels.\n",
    "sp1[:10000].stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Last 10,000 channels.\n",
    "sp1[-10000:].stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "There is a significant continuum visible in the spectrum, with a value of ${\\approx}270$ mK, but the two sides differ a bit, in the sense there is slight increase towards higher channels. This is also visible in the previous plot.\n",
    "\n",
    "The rms levels are very similar, at 0.0712 K and 0.0719 K respectively.\n",
    "\n",
    "It is possible to compute the statistics over a \"rolled\" version of the spectrum.\n",
    "That is, before computing the statistics, the values from channel `i+roll` are subtracted from the values of channel `i`.\n",
    "This accomplished using the `roll` argument in the call to {py:class}`stats <dysh.spectra.spectrum.Spectrum.stats>`.\n",
    "When using ``roll!=0`` the rms is divided by $\\sqrt{2}$ to account for the subtraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sp1[:10000].stats(roll=2)[\"rms\"])\n",
    "print(sp1[-10000:].stats(roll=2)[\"rms\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "Here we see the rolled RMS is very similar to the direct RMS, a sign that there is little or no correlation between channels, and that there are no large scale variations in the baseline. This brings us to the next function, {py:class}`roll <dysh.spectra.spectrum.Spectrum.roll>`:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "## Roll\n",
    "\n",
    "The {py:class}`roll <dysh.spectra.spectrum.Spectrum.roll>` method compares the rms in the spectrum to the rms obtained after \"rolling\" the data by `roll` channels.\n",
    "This method is useful for assessing if there are channel-to-channel correlations. In the abscence of correlations the result should be close to unity. \n",
    "Correlations will drive the results away from unity.\n",
    "However, the results from {py:class}`roll <dysh.spectra.spectrum.Spectrum.roll>` are also affected by slow variations in the data, as is the case with this spectrum.\n",
    "We thus compare the first and second half."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "sp1[:10000].roll(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "sp1[-10000:].roll(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "Here one can argue there is no correllation between channels, and there is little large scale variation in the baseline. Note we have not subtracted a baseline, so we will need to do this again later in the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "##  Radiometer Equation\n",
    "\n",
    "For a given $T_{sys}$, channel width $\\Delta f$ and observing time $\\Delta t$ the radiometer equation predicts the expected noise as:\n",
    "$$\n",
    "  \\Delta T = {  { T_{sys} } \\over \\sqrt{ \\Delta f \\Delta t } }\n",
    "$$\n",
    "The {py:class}`radiometer <dysh.spectra.spectrum.Spectrum.radiometer>` method will return the ratio of the measured noise to this expected noise.\n",
    "In the abscence of artifacts, the result should be unity.\n",
    "Deviations from unity might indicate that the noise properties do not follow those of a normal distribution.\n",
    "\n",
    "For example, if we blindly compute this test we will get a value larger than one, because of line emission between channels 10000 and 13000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "sp1.radiometer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "When we compute it on line-free channels the results are closer to unity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sp1[:10000].radiometer(), sp1[-10000:].radiometer())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "However, the measured noise (rms) is still ${\\approx}6\\%$ larger than expected.\n",
    "\n",
    "For comparison, we compute this statistic in the case of a purely Gaussian signal.\n",
    "We do this using the {py:class}`fake_spectrum <dysh.spectra.spectrum.Spectrum.fake_spectrum>` method, which returns a spectrum filled with Gaussian noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "Spectrum.fake_spectrum(nchan=32768, seed=123).radiometer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "The exact value is a function of the number of channels in the spectrum, and it goes as $1/\\sqrt{N}$. \n",
    "Experiments showed that for nchan=32768 the rms in this ratio is about 0.004.\n",
    "\n",
    "## Normalness\n",
    "\n",
    "The {py:class}`normalness <dysh.spectra.spectrum.Spectrum.normalness>` method gives the likelihood that the spectrum data is drawn from a normal distribution.\n",
    "Under the hood this method computes the Anderson-Darling statistic and returns the p-value of the likelihood that the data is normally distributed.\n",
    "A p-value larger than 0.05 indicates that the data is consistent with being drawn from a normal distribution.\n",
    "\n",
    "We start by computing the normalness test for the line-free regions, and then we compute it for the whole spectrum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sp1[:10000].normalness())\n",
    "print(sp1[-10000:].normalness())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "These values are larger than 0.05, so the line-free regions are consistent with Gaussian noise.\n",
    "For amusement, the whole spectrum:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sp1.normalness())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {},
   "source": [
    "In this case the p-value is lower than 0.05, indicating that the null-hyphotesis can be rejected, that is, the data is not drawn from a normal distribution.\n",
    "That is the case because of the line between channels 10000 and 13000."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29",
   "metadata": {},
   "source": [
    "## Baseline Subtraction\n",
    "\n",
    "The remaining data quality tests, the signal-to-noise ratio and signal ratio, only make sense if the data has no continuum.\n",
    "In this case that requires subtracting a baseline from the data.\n",
    "\n",
    "We know that there is a line between channels 10000 and 13000, so we exclude these channels from the baseline fit using the `exclude` argument of {py:class}`Spectrum.baseline <dysh.spectra.spectrum.Spectrum.baseline>`.\n",
    "We saw earlier that there's a slope to the data, so we use a degree 2 polynomial for the baseline model, to to ensure any curvature is removed as well. Again, these things can later be tested.\n",
    "We remove the best fit polynomial model from the data (`remove=True`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "sp1.baseline(degree=2, model=\"poly\", exclude=[10000,13000], remove=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31",
   "metadata": {},
   "source": [
    "Plot the baseline subtracted spectrum and print its statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "sp1.plot(xaxis_unit='chan');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "sp1[:10000].stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "sp1[-10000:].stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35",
   "metadata": {},
   "source": [
    "## snr: Signal-to-Noise Ratio\n",
    "\n",
    "The {py:class}`snr <dysh.spectra.spectrum.Spectrum.snr>` method computes the signal-to-noise ratio of the spectrum.\n",
    "This can be done in two ways: channel based and flux based.\n",
    "For the latter a section of the spectrum where the signal is expected has to be selected.\n",
    "For the channel based analysis, it will compute the ratio between the maximum value (``peak=True``, default) and the noise.\n",
    "For an absorption signal one can use ``peak=False`` where the minimum is used instead.\n",
    "\n",
    "For pure noise in a channel based comparision (the default) we would expect the signal-to-noise to be around 4, higher for higher number of channels, as can be computed via the error function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sp1[:10000].snr(), sp1[-10000:].snr())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37",
   "metadata": {},
   "source": [
    "Now we repeat the ``snr`` call, but using the flux instead.\n",
    "We show the results for the line-free regions of the spectrum and for the section with the line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sp1[:10000].snr(flux=True))\n",
    "print(sp1[-10000:].snr(flux=True))\n",
    "print(sp1[10000:13000].snr(flux=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39",
   "metadata": {},
   "source": [
    "The line-free regions have a signal-to-noise of $<0.5$, so no signal in them.\n",
    "Channels 10000 to 13000 have a signal-to-noise ratio of $47$. Really it should be called flux-to-error ratio.\n",
    "\n",
    "Applying this to the whole spectrum, we still get a respectable ratio of over 5:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "sp1.snr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41",
   "metadata": {},
   "source": [
    "## sratio:  Signal Ratio\n",
    "\n",
    "The {py:class}`snr <dysh.spectra.spectrum.Spectrum.sratio>` signal ratio is defined as the sum between the positive and negative sum of the signals, normalized by the difference of both. This results in a dimensionless number between -1 and 1, where -1 means a pure absorption signal, 0 pure noise, and 1 pure emission line:\n",
    "$$\n",
    "     S_r = {{ P_{sum}+ N_{sum} } \\over {P_{sum} - N_{sum}}}\n",
    "$$\n",
    "with $P_{sum}$ the sum of all the channels with positive values and $N_{sum}$ the sum of all the channels with negative values.\n",
    "Note that $N_{sum}$ is negative.\n",
    "\n",
    "We compute this for the line-free channels, where we expect values close to zero (no signal)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sp1[:10000].sratio())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sp1[-10000:].sratio())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44",
   "metadata": {},
   "source": [
    "And now the channels with the line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sp1[10000:13000].sratio())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46",
   "metadata": {},
   "source": [
    "In this case we have a value of $0.74$, close to unity, indicating an emission line."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47",
   "metadata": {},
   "source": [
    "## Repeat statistics, roll and radiometer\n",
    "\n",
    "Now that the spectrum has been baseline subtracted we can repeat the analysis carried out above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# redo the tests\n",
    "print(sp1[:10000].stats())\n",
    "print(sp1[:10000].stats(roll=1))\n",
    "print(\"ROLL\",sp1[:10000].roll(4))\n",
    "\n",
    "\n",
    "print(sp1[-10000:].stats())\n",
    "print(sp1[-10000:].stats(roll=1))\n",
    "print(\"ROLL\",sp1[-10000:].roll(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sp1[:10000].radiometer(), sp1[-10000:].radiometer())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50",
   "metadata": {},
   "source": [
    "Curious how the radiometer equation holds as function of time?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51",
   "metadata": {},
   "outputs": [],
   "source": [
    "for scan in [51,53,55,57]:\n",
    "    sp2 = sdfits.getps(scan=scan, ifnum=0, plnum=0, fdnum=0).timeaverage()[5000:30000]\n",
    "    print(scan, sp2[:10000].radiometer(), sp2[-10000:].radiometer())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52",
   "metadata": {},
   "source": [
    "So we can conclude it did not change behavior during this observation, but there is a clear 5-6% deviation from an ideal telescope."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53",
   "metadata": {},
   "source": [
    "## Smoothing\n",
    "\n",
    "Smoothing should give us a much clearer detection.\n",
    "We smooth the data using a Hanning kernel with a width of 50 channels.\n",
    "Lets see how the previous measures live of to this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "print_tsys",
     "test"
    ]
   },
   "outputs": [],
   "source": [
    "n = 50\n",
    "method = 'hanning'\n",
    "sp1s = sp1.smooth(method, n)\n",
    "\n",
    "sp1s.plot(xaxis_unit='chan')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55",
   "metadata": {},
   "source": [
    "The line is now between channels 200 and 260.\n",
    "\n",
    "Lets print the rms for this smoothed signal. \n",
    "Unsmoothed we found 0.07 K so we should expect $\\sqrt{50}$ better, or about 0.01 K."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sp1s[:200].stats()[\"rms\"], sp1s[-200:].stats()[\"rms\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57",
   "metadata": {},
   "source": [
    "Smoothing reduced the noise as expected.\n",
    "\n",
    "Now the radiometer equation test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sp1s[:200].radiometer())\n",
    "print(sp1s[-200:].radiometer())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59",
   "metadata": {},
   "source": [
    "In this case the test suggests that the data is worse than before (it was $5\\%$ higher, now it is $11\\%$).\n",
    "This could be an artifact of ``dysh``, and is being investigated in issue 917\n",
    "\n",
    "Now the signal-to-noise ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Signal-to-Noise by channel\")\n",
    "print(sp1s[:200].snr(peak=True), sp1s[:200].snr(peak=False), 'left side')\n",
    "print(sp1s[-200:].snr(peak=True), sp1s[-200:].snr(peak=False), 'right side')\n",
    "print(sp1s[200:260].snr(peak=True), sp1s[200:260].snr(peak=False), 'central signal portion')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Signal-to-Noise by flux\")\n",
    "print(sp1s[:200].snr(flux=True), 'left side')\n",
    "print(sp1s[-200:].snr(flux=True), 'right side')\n",
    "print(sp1s[200:260].snr(flux=True), 'central signal portion')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62",
   "metadata": {},
   "source": [
    "Notice that the signal-to-noise in the line intensity is now lower than before (it was ${\\approx}47$).\n",
    "That is because the ``snr`` method uses the data itself to determine the noise.\n",
    "Since we are using a channel range that mostly contains signal, the noise estimate is higher, thus reducing the signal-to-noise ratio.\n",
    "We can give our own estimate of the noise using the ``rms`` parameter when calling ``snr``.\n",
    "Like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sp1s[200:260].snr(flux=True, rms=sp1s[-200:].stats()[\"rms\"]), 'center signal portion with given rms')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64",
   "metadata": {},
   "source": [
    "This is closer to the previous estimate.\n",
    "It also shows that smoothing the data does not improve the signal-to-noise ratio on the line intensity for this velocity resolved line.\n",
    "\n",
    "And the signal ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65",
   "metadata": {},
   "outputs": [],
   "source": [
    "sp1s[200:260].sratio()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66",
   "metadata": {},
   "source": [
    "a value very close to 1, so a clear signal.\n",
    "\n",
    "This brings up the question of statistical significance. Unlike the `normalness()` function, we don't get a p-value out of this. We would have to compute this ourselves.\n",
    "\n",
    "Without much more discussion, we offer the following experiment. Be aware, this cell can take a few minutes to compute depending on the value of `m`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "m=1000                # number of experiments\n",
    "d=np.zeros(m)         # array containing the sratio values\n",
    "n=32768               # largest size of spectrum\n",
    "\n",
    "\n",
    "for nchan in [n, n//4, n//4//4, n//4//4//4]:\n",
    "    for i in range(m):\n",
    "        sp = Spectrum.fake_spectrum(nchan=nchan, seed=i, use_wcs=False)\n",
    "        sp.data = sp.data - 0.1     # current fake_spectrum has hardcoded mean 0.1\n",
    "        d[i] = sp.sratio()\n",
    "    print(d.mean(),d.std(),nchan,m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot histogram of last nchan loop with 512 channels\n",
    "import matplotlib.pyplot as plt\n",
    "plt.hist(d, bins=\"auto\");\n",
    "plt.xlabel(\"sratio value\");\n",
    "plt.ylabel(\"Counts\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69",
   "metadata": {},
   "source": [
    "The RMS follows the expected $1/\\sqrt{N}$ behavior, and for given $N$ one can assign a p-value based on the error function if this distribution is normal.  We leave this as an excersize for the reader."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70",
   "metadata": {},
   "source": [
    "## Curve of Growth\n",
    "\n",
    "The [Curve of Growth method](https://dysh.readthedocs.io/en/latest/explanations/cog/index.html) ([Yu et al. 2020](https://ui.adsabs.harvard.edu/abs/2020ApJ...898..102Y/abstract)) also lists lots of interesting properties that can be used in some of the quality assessment functions we have discussed above.\n",
    "\n",
    "We merely show the result of the `cog` function here, and plot the spectrum now in units of km/s:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71",
   "metadata": {},
   "outputs": [],
   "source": [
    "sp1s.cog()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72",
   "metadata": {},
   "outputs": [],
   "source": [
    "sp1s.plot(xaxis_unit='km/s')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  },
  "toc": {
   "base_numbering": 0
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
