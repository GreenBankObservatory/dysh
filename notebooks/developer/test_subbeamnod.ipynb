{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78f4da54-2716-4947-91a0-58d5ed81f660",
   "metadata": {},
   "source": [
    "My attempt at reproducing Dave's `snodka` function. Dave's function will be wrong when the atmosphere is changing faster than a scan.\n",
    "\n",
    "After the first half of the notebook, I try to do it on a per cycle basis and use `dysh` functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46687bc3-25af-4312-ab56-d96c887d202f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb1dffc-45dd-4a98-9bc6-8e4ed0bf5283",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from astropy.io import fits\n",
    "from astropy import units as u\n",
    "\n",
    "from dysh.spectra import core as sc\n",
    "from dysh.spectra.scan import GBTTPScan\n",
    "from dysh.fits.gbtfitsload import GBTFITSLoad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f29e7ea-7e6e-43ba-8ed6-c2ccf71ce4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_query(query, op=\"and\"):\n",
    "    \"\"\" Takes a dictionary with keys as SDFITS columns\n",
    "    and whose values are a tuple with the condition and \n",
    "    the required value and concatenates them using the\n",
    "    `op` operator.\n",
    "    \"\"\"\n",
    "    q = \"\"\n",
    "    for i,(k,v) in enumerate(query.items()):\n",
    "        q += f\"{k} {v[0]} {v[1]} \"\n",
    "        if i < len(query) - 1:\n",
    "            q += f\"{op} \"\n",
    "    return q\n",
    "\n",
    "\n",
    "def select_rows(df, query, op=\"and\"):\n",
    "    \"\"\" Returns a list with the rows of a `pandas.DataFrame`\n",
    "    that fulfill the query.\n",
    "    See `parse_query` for details on how to define the query.\n",
    "    \"\"\"\n",
    "\n",
    "    q = parse_query(query, op=op)\n",
    "    return np.array(list(df.query(q).index))\n",
    "\n",
    "\n",
    "def tsys_vec(cal_on, cal_off, fedge=10, ch0=None, chf=None):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "\n",
    "    nchan = cal_on[\"DATA\"].shape[1]\n",
    "    if ch0 == None:\n",
    "        ch0 = nchan // fedge\n",
    "    if chf == None:\n",
    "        chf = nchan - ch0 + 1\n",
    "    chrng = slice(ch0,chf,1)\n",
    "\n",
    "    tcal = cal_on[\"TCAL\"]\n",
    "    meanoff = cal_off[\"DATA\"][:,chrng]\n",
    "    meandiff = cal_on[\"DATA\"][:,chrng] - cal_off[\"DATA\"][:,chrng]\n",
    "\n",
    "    tsys = ( meanoff / meandiff * tcal[:,np.newaxis] + tcal[:,np.newaxis]/2.0 )\n",
    "\n",
    "    return tsys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70800974-6d9f-4c54-92ca-47be8e2eb541",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/data/gbt/examples/subbeamnod-Ka/\"\n",
    "sdf_file = f\"{path}/data/TRCO_230413_Ka.raw.vegas/TRCO_230413_Ka.raw.vegas.A.fits\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba8aea8-b7f3-4443-b0ee-5b5a38298d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf = GBTFITSLoad(sdf_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ac6025-c775-4bae-a976-a2470e277aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define what we are calibrating.\n",
    "scan = 43\n",
    "ifnum = 0\n",
    "fdnum = 1 # Remember that Ka is special because its beams are switched! It is now fixed, yay!\n",
    "plnum = 0\n",
    "bintable = 0\n",
    "w = \"tsys\"\n",
    "docal = True\n",
    "\n",
    "# Select data.\n",
    "q = {\"SCAN\": (\"in\", f\"[{scan}]\"), \n",
    "     \"IFNUM\": (\"in\", f\"[{ifnum}]\"), \n",
    "     \"FDNUM\": (\"in\", f\"[{fdnum}]\"), \n",
    "     \"PLNUM\": (\"==\", plnum), \n",
    "     \"SUBREF_STATE\": (\"==\", -1)}\n",
    "sig_rows = select_rows(sdf._ptable[bintable], q)\n",
    "q = {\"SCAN\": (\"in\", f\"[{scan}]\"), \n",
    "     \"IFNUM\": (\"in\", f\"[{ifnum}]\"), \n",
    "     \"FDNUM\": (\"in\", f\"[{fdnum}]\"), \n",
    "     \"PLNUM\": (\"==\", plnum), \n",
    "     \"SUBREF_STATE\": (\"==\", 1)}\n",
    "ref_rows = select_rows(sdf._ptable[bintable], q)\n",
    "\n",
    "# Average.\n",
    "def time_average(table):\n",
    "    wt = np.empty(len(table), dtype='d')\n",
    "    wt[:] = table[\"EXPOSURE\"].astype('d')*abs(table[\"CDELT1\"]).astype('d')/table[\"TSYS\"].astype('d')\n",
    "    return np.average(table[\"DATA\"], axis=0, weights=wt)\n",
    "\n",
    "ref_avg = time_average(sdf._hdu[bintable+1].data[ref_rows])\n",
    "sig_avg = time_average(sdf._hdu[bintable+1].data[sig_rows])\n",
    "\n",
    "# Get TSYS.\n",
    "fulltp = sdf.gettp(scan,sig=None,cal=None,\n",
    "                    bintable=bintable,fdnum=fdnum,\n",
    "                    plnum=plnum,ifnum=ifnum,\n",
    "                    weight=w,calibrate=docal).timeaverage(weights=w)\n",
    "\n",
    "# Good old calibration.\n",
    "cal = (sig_avg - ref_avg)/ref_avg * fulltp.meta['TSYS']\n",
    "\n",
    "# Now we should make a new SDFITS row with the calibrated data \n",
    "# and the corresponding updated data and metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f220b33-c52f-4bf6-bcb9-338223fa2ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the result from GBTIDL.\n",
    "gbtidl_file = f\"{path}/outputs/snodka_scan_43_fdnum_1_plnum_0.fits\"\n",
    "gbtidl_file=\"/home/mpound/src/dysh/src/dysh/spectra/tests/data/snodka_scan_43_fdnum_1_plnum_0.fits\"\n",
    "hdu_ = fits.open(gbtidl_file)\n",
    "gbtidl_sbn = hdu_[1].data[\"DATA\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe19cf4b-b5e1-4a1b-9ac2-044eebc2d13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare.\n",
    "diff = cal - gbtidl_sbn\n",
    "print(f\"Mean diff: {np.nanmean(diff)}\")\n",
    "print(f\"Median diff: {np.nanmedian(diff)}\")\n",
    "\n",
    "# Allways look at it.\n",
    "plt.figure()\n",
    "plt.subplot(211)\n",
    "plt.plot(cal, label=\"dysh\")\n",
    "plt.plot(gbtidl_sbn, alpha=0.5, label=\"GBTIDL\")\n",
    "plt.legend()\n",
    "plt.ylabel(\"Antenna temperature (K)\")\n",
    "plt.xlabel(\"Channel number\")\n",
    "plt.subplot(212)\n",
    "plt.plot(cal - gbtidl_sbn, c='k')\n",
    "plt.ylabel(\"Difference (K)\")\n",
    "plt.xlabel(\"Channel number\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16333e15-3637-478c-91f0-1aaf364f5099",
   "metadata": {},
   "source": [
    "Now, the correct way of doing this is to actually do the calibration per cycle. Also, take care that you pair signal and reference cycles properly, specially if you have less reference cycles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a06153-c33e-4c6b-9d8e-2616ff68e480",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select data.\n",
    "q = {\"SCAN\": (\"in\", f\"[{scan}]\"), \n",
    "     \"IFNUM\": (\"in\", f\"[{ifnum}]\"), \n",
    "     \"FDNUM\": (\"in\", f\"[{fdnum}]\"), \n",
    "     \"PLNUM\": (\"==\", plnum)}\n",
    "rows = select_rows(sdf._ptable[bintable], q)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(rows, sdf._hdu[bintable+1].data[rows][\"SUBREF_STATE\"], 'ko')\n",
    "calon = (sdf._hdu[bintable+1].data[rows][\"CAL\"]==\"T\")\n",
    "plt.plot(rows[calon], np.ones(calon.sum()), \"r.\")\n",
    "caloff = (sdf._hdu[bintable+1].data[rows][\"CAL\"]==\"F\")\n",
    "plt.plot(rows[caloff], -np.ones(caloff.sum()), \"b.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95be95b3-9052-4bf1-a81c-4312f20cc3fd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "q = {\"SCAN\": (\"in\", f\"[{scan}]\"), \n",
    "     \"IFNUM\": (\"in\", f\"[{ifnum}]\"), \n",
    "     \"FDNUM\": (\"in\", f\"[{fdnum}]\"), \n",
    "     \"PLNUM\": (\"==\", plnum), \n",
    "     \"SUBREF_STATE\": (\"==\", -1),\n",
    "     \"CAL\": (\"==\", \"'T'\")}\n",
    "sig_on_rows = select_rows(sdf._ptable[bintable], q)\n",
    "q.update({\"CAL\": (\"==\", \"'F'\")})\n",
    "sig_off_rows = select_rows(sdf._ptable[bintable], q)\n",
    "q.update({\"SUBREF_STATE\": (\"==\", 1)})\n",
    "ref_off_rows = select_rows(sdf._ptable[bintable], q)\n",
    "q.update({\"CAL\": (\"==\", \"'T'\")})\n",
    "ref_on_rows = select_rows(sdf._ptable[bintable], q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4524834f-13a1-45cf-93a6-2fe694e7c186",
   "metadata": {},
   "outputs": [],
   "source": [
    "def consecutive(data, stepsize=1):\n",
    "    return np.split(data, np.where(np.diff(data) >= stepsize)[0]+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5dcee0-e787-4f3a-b5ea-78292f43f907",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This should be tested in more cases.\n",
    "stepsize = len(sdf.udata(0,\"IFNUM\"))*len(sdf.udata(0,\"PLNUM\"))*2 + 1\n",
    "stepsize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba23617-aa7c-43a1-8302-63cf021fae5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_on_groups = consecutive(ref_on_rows, stepsize=stepsize)\n",
    "sig_on_groups = consecutive(sig_on_rows, stepsize=stepsize)\n",
    "ref_off_groups = consecutive(ref_off_rows, stepsize=stepsize)\n",
    "sig_off_groups = consecutive(sig_off_rows, stepsize=stepsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae6cfdc-9fa2-45c4-afd7-9f3162342078",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test case.\n",
    "if False:\n",
    "    print(len(ref_on_groups))\n",
    "    del ref_on_groups[-1]\n",
    "    del ref_on_groups[-1]\n",
    "    print(len(ref_on_groups))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd37423-fa29-4dc2-b918-ea687303bfd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure we have enough signal and reference pairs.\n",
    "# Same number of cycles or less signal cycles.\n",
    "if len(sig_on_groups) <= len(ref_on_groups):\n",
    "    pairs = {i : i for i in range(len(sig_on_groups))}\n",
    "# One more signal cycle. Re-use one reference cycle.\n",
    "elif len(sig_on_groups) - 1 == len(ref_on_groups):\n",
    "    pairs = {i : i for i in range(len(sig_on_groups))}\n",
    "    pairs[len(sig_on_groups) - 1] = len(ref_on_groups) - 1\n",
    "else:\n",
    "    e = f\"\"\"There are {len(sig_on_groups)} and {len(ref_on_groups)} signal and reference cycles.\n",
    "            Try using the per-scan option\"\"\"\n",
    "    raise ValueError(e)\n",
    "pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3132b94-e548-40c3-9ee1-516e45607178",
   "metadata": {},
   "outputs": [],
   "source": [
    "nchan = int(sdf._ptable[bintable][\"TDIM7\"][0][1:-1].split(\",\")[0])\n",
    "ta = np.empty((len(sig_on_groups)), dtype=object)\n",
    "ta_avg = np.zeros(nchan, dtype='d')\n",
    "wt_avg = 0.0 #np.empty(nchan, dtype='d')\n",
    "groups_zip = zip(ref_on_groups, sig_on_groups, ref_off_groups, sig_off_groups)\n",
    "\n",
    "for i,(rgon,sgon,rgoff,sgoff) in enumerate(groups_zip):\n",
    "    \n",
    "    # #print(rgon)\n",
    "    # ref_on = sdf._hdu[bintable+1].data[rgon]\n",
    "    # ref_off = sdf._hdu[bintable+1].data[rgoff]\n",
    "    # tcal = ref_on[\"TCAL\"]\n",
    "    # tsys = tsys_vec(ref_on, ref_off) #sc.mean_tsys(ref_on[\"DATA\"], ref_off[\"DATA\"], tcal, fedge=10)\n",
    "    # #tsys_ = np.array([sc.mean_tsys(ref_on[\"DATA\"][i], ref_off[\"DATA\"][i], tcal[0]) for i in range(len(rgon))])\n",
    "    # ref_on[\"TSYS\"] = tsys.mean(axis=1)\n",
    "    # ref_off[\"TSYS\"] = tsys.mean(axis=1)\n",
    "    # ref_on_avg = time_average(ref_on)\n",
    "    # ref_off_avg = time_average(ref_off)\n",
    "    # ref_avg = (ref_on_avg + ref_off_avg)\n",
    "    # #ref = \n",
    "    \n",
    "    # Do it the dysh way.\n",
    "    calrows = {\"ON\": rgon, \"OFF\": rgoff}\n",
    "    tprows = np.sort(np.hstack((rgon, rgoff)))\n",
    "    reftp = GBTTPScan(sdf,43,\"BOTH\",\"BOTH\",tprows,calrows,0,True)\n",
    "    ref_avg = reftp.timeaverage()\n",
    "    calrows = {\"ON\": sgon, \"OFF\": sgoff}\n",
    "    tprows = np.sort(np.hstack((sgon, sgoff)))\n",
    "    sigtp = GBTTPScan(sdf,43,\"BOTH\",\"BOTH\",tprows,calrows,0,True)\n",
    "    sig_avg = sigtp.timeaverage()\n",
    "    # Combine sig and ref.\n",
    "    ta[i] = deepcopy(sig_avg)\n",
    "    ta[i] = ta[i].new_flux_unit(\"K\", suppress_conversion=True)\n",
    "    ta[i]._data = ((sig_avg - ref_avg)/ref_avg).flux.value * ref_avg.meta['WTTSYS'] * u.K\n",
    "    ta[i].meta[\"TUNIT7\"] = \"Ta\"\n",
    "    ta[i].meta[\"TSYS\"] = ref_avg.meta['WTTSYS']\n",
    "\n",
    "    wt_avg += ta[i].meta[\"TSYS\"]**-2.\n",
    "    ta_avg[:] += ta[i].flux.value * ta[i].meta[\"TSYS\"]**-2.\n",
    "\n",
    "ta_avg = ta_avg / wt_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c9ba916-d81a-471d-a436-9382692a26a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For fun, lets also try the current dysh version.\n",
    "sbn = sdf.subbeamnod(43, sig=None, cal=None,\n",
    "                     ifnum=0, fdnum=1, calibrate=True,\n",
    "                     weights='tsys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5630f0-4791-4454-8d9c-750d309f6983",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(dpi=150)\n",
    "plt.subplot(211)\n",
    "for i in range(len(ta)):\n",
    "    plt.plot(ta[i].flux.value, label=i)\n",
    "plt.plot(ta_avg, label='average')\n",
    "plt.plot(gbtidl_sbn, label=\"GBTIDL\")\n",
    "plt.plot(sbn.flux.value, label=\"dysh\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Channel number\")\n",
    "plt.ylabel(\"Antenna temperature (K)\")\n",
    "plt.subplot(212)\n",
    "plt.plot(gbtidl_sbn/np.nanmax(gbtidl_sbn)*np.nanmax(ta_avg) - ta_avg, label=\"GBTIDL-this version\")\n",
    "plt.plot(gbtidl_sbn/np.nanmax(gbtidl_sbn)*np.nanmax(sbn.flux.value) - sbn.flux.value, label=\"GBTIDL-dysh\")\n",
    "plt.plot(ta_avg/np.nanmax(ta_avg)*np.nanmax(sbn.flux.value) - sbn.flux.value, label=\"dysh-this version\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Channel number\")\n",
    "plt.ylabel(\"Difference (K)\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cddef918-0fcc-4552-9789-5336a3e53c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which one is less noisy?\n",
    "x = np.arange(nchan)\n",
    "s = slice(460,600,1)\n",
    "\n",
    "pfit = np.polyfit(x[s], ta_avg[s], 1)\n",
    "pval = np.poly1d(pfit)(x[s])\n",
    "ta_ = ta_avg[s] - pval\n",
    "print(f\"rms in this version: {ta_.std()}\")\n",
    "\n",
    "pfit = np.polyfit(x[s], sbn.flux.value.astype('d')[s], 1)\n",
    "pval = np.poly1d(pfit)(x[s])\n",
    "sbn_ = sbn.flux.value[s] - pval\n",
    "print(f\"rms in dysh version: {sbn_.std()}\")\n",
    "\n",
    "pfit = np.polyfit(x[s], gbtidl_sbn[s], 1)\n",
    "pval = np.poly1d(pfit)(x[s])\n",
    "gbtidl_ = gbtidl_sbn[s] - pval\n",
    "print(f\"rms in dysh version: {gbtidl_.std()}\")\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(ta_, label=\"this\")\n",
    "plt.plot(sbn_, label=\"dysh\")\n",
    "plt.plot(gbtidl_, label=\"GBTIDL\")\n",
    "plt.xlabel(\"Channel\")\n",
    "plt.ylabel(r\"Baseline subtracted $T_{\\rm{A}}$ (K)\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5fa4189-dad4-4d6d-9f06-89e03cd2baec",
   "metadata": {},
   "source": [
    "In the end, they all seem to perform similarly. To really understand which one is better, we should use synthetic data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5982d6-4aa6-4f81-befc-4d2893456010",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
